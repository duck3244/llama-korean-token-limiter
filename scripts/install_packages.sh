#!/bin/bash
# í•œêµ­ì–´ Token Limiter íŒ¨í‚¤ì§€ ì„¤ì¹˜ ìŠ¤í¬ë¦½íŠ¸

set -e

echo "ğŸ Python íŒ¨í‚¤ì§€ ë‹¨ê³„ë³„ ì„¤ì¹˜ ì‹œì‘"
echo "================================="

# ìƒ‰ìƒ ì •ì˜
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# ê°€ìƒí™˜ê²½ í™•ì¸
if [[ "$VIRTUAL_ENV" == "" ]]; then
    echo -e "${RED}âŒ ê°€ìƒí™˜ê²½ì´ í™œì„±í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤${NC}"
    echo "ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ê°€ìƒí™˜ê²½ì„ í™œì„±í™”í•˜ì„¸ìš”:"
    echo "source venv/bin/activate"
    exit 1
fi

echo -e "${GREEN}âœ… ê°€ìƒí™˜ê²½ í™œì„±í™”ë¨: $VIRTUAL_ENV${NC}"

# GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
if command -v nvidia-smi &> /dev/null; then
    GPU_AVAILABLE=true
    echo -e "${GREEN}ğŸ® GPU ê°ì§€ë¨${NC}"
    nvidia-smi --query-gpu=name,memory.total --format=csv,noheader,nounits | head -1
else
    GPU_AVAILABLE=false
    echo -e "${YELLOW}âš ï¸ GPUë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CPU ëª¨ë“œë¡œ ì„¤ì¹˜í•©ë‹ˆë‹¤.${NC}"
fi

# 1ë‹¨ê³„: ê¸°ë³¸ ë„êµ¬ ì—…ê·¸ë ˆì´ë“œ
echo -e "\n${BLUE}ğŸ“¦ 1ë‹¨ê³„: ê¸°ë³¸ ë„êµ¬ ì—…ê·¸ë ˆì´ë“œ${NC}"
pip install --upgrade pip wheel setuptools
echo -e "${GREEN}âœ… ê¸°ë³¸ ë„êµ¬ ì—…ê·¸ë ˆì´ë“œ ì™„ë£Œ${NC}"

# 2ë‹¨ê³„: PyTorch ì„¤ì¹˜
echo -e "\n${BLUE}ğŸ”¥ 2ë‹¨ê³„: PyTorch ì„¤ì¹˜${NC}"
if [ "$GPU_AVAILABLE" = true ]; then
    echo "CUDA ë²„ì „ìš© PyTorch ì„¤ì¹˜ ì¤‘..."
    pip install torch==2.1.0 torchvision==0.16.0 torchaudio==2.1.0 --index-url https://download.pytorch.org/whl/cu121
else
    echo "CPU ë²„ì „ PyTorch ì„¤ì¹˜ ì¤‘..."
    pip install torch==2.1.0 torchvision==0.16.0 torchaudio==2.1.0 --index-url https://download.pytorch.org/whl/cpu
fi

# PyTorch ì„¤ì¹˜ í™•ì¸
python -c "import torch; print(f'âœ… PyTorch {torch.__version__} ì„¤ì¹˜ ì™„ë£Œ')"
if [ "$GPU_AVAILABLE" = true ]; then
    python -c "import torch; print(f'ğŸ® CUDA ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.is_available()}')"
fi

# 3ë‹¨ê³„: vLLM ì„¤ì¹˜ (GPUê°€ ìˆëŠ” ê²½ìš°ë§Œ)
if [ "$GPU_AVAILABLE" = true ]; then
    echo -e "\n${BLUE}ğŸš€ 3ë‹¨ê³„: vLLM ì„¤ì¹˜${NC}"
    pip install vllm==0.2.7
    echo -e "${GREEN}âœ… vLLM ì„¤ì¹˜ ì™„ë£Œ${NC}"
else
    echo -e "\n${YELLOW}âš ï¸ 3ë‹¨ê³„: vLLM ê±´ë„ˆë›°ê¸° (GPU ì—†ìŒ)${NC}"
fi

# 4ë‹¨ê³„: Flash Attention ì„¤ì¹˜ (ì„ íƒì‚¬í•­, GPUê°€ ìˆëŠ” ê²½ìš°ë§Œ)
if [ "$GPU_AVAILABLE" = true ]; then
    echo -e "\n${BLUE}âš¡ 4ë‹¨ê³„: Flash Attention ì„¤ì¹˜ (ì„ íƒì‚¬í•­)${NC}"
    pip install flash-attn==2.3.4 --no-build-isolation || {
        echo -e "${YELLOW}âš ï¸ Flash Attention ì„¤ì¹˜ ì‹¤íŒ¨ (ì„ íƒì‚¬í•­ì´ë¯€ë¡œ ê³„ì† ì§„í–‰)${NC}"
    }
    
    echo -e "\n${BLUE}ğŸ”§ xformers ì„¤ì¹˜ (ì„ íƒì‚¬í•­)${NC}"
    pip install xformers==0.0.22.post7 || {
        echo -e "${YELLOW}âš ï¸ xformers ì„¤ì¹˜ ì‹¤íŒ¨ (ì„ íƒì‚¬í•­ì´ë¯€ë¡œ ê³„ì† ì§„í–‰)${NC}"
    }
else
    echo -e "\n${YELLOW}âš ï¸ 4ë‹¨ê³„: Flash Attention ê±´ë„ˆë›°ê¸° (GPU ì—†ìŒ)${NC}"
fi

# 5ë‹¨ê³„: ê¸°ë³¸ íŒ¨í‚¤ì§€ ì„¤ì¹˜
echo -e "\n${BLUE}ğŸ“š 5ë‹¨ê³„: ê¸°ë³¸ íŒ¨í‚¤ì§€ ì„¤ì¹˜${NC}"
pip install -r requirements.txt
echo -e "${GREEN}âœ… ê¸°ë³¸ íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì™„ë£Œ${NC}"

# 6ë‹¨ê³„: í•œêµ­ì–´ ì²˜ë¦¬ íŒ¨í‚¤ì§€ ì„¤ì¹˜ (ì„ íƒì‚¬í•­)
echo -e "\n${BLUE}ğŸ‡°ğŸ‡· 6ë‹¨ê³„: í•œêµ­ì–´ ì²˜ë¦¬ íŒ¨í‚¤ì§€ ì„¤ì¹˜ (ì„ íƒì‚¬í•­)${NC}"
read -p "í•œêµ­ì–´ í˜•íƒœì†Œ ë¶„ì„ íŒ¨í‚¤ì§€(KoNLPy, MeCab)ë¥¼ ì„¤ì¹˜í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): " -n 1 -r
echo
if [[ $REPLY =~ ^[Yy]$ ]]; then
    # MeCab ì‹œìŠ¤í…œ íŒ¨í‚¤ì§€ ì„¤ì¹˜ í™•ì¸
    if command -v mecab &> /dev/null; then
        pip install konlpy==0.6.0 mecab-python3==1.0.6
        echo -e "${GREEN}âœ… í•œêµ­ì–´ ì²˜ë¦¬ íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì™„ë£Œ${NC}"
    else
        echo -e "${YELLOW}âš ï¸ MeCabì´ ì‹œìŠ¤í…œì— ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤${NC}"
        echo "ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì„¤ì¹˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:"
        echo "sudo apt install mecab mecab-ko mecab-ko-dic"
        pip install konlpy==0.6.0 || echo "KoNLPyë§Œ ì„¤ì¹˜í–ˆìŠµë‹ˆë‹¤"
    fi
else
    echo "í•œêµ­ì–´ ì²˜ë¦¬ íŒ¨í‚¤ì§€ ì„¤ì¹˜ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤."
fi

# 7ë‹¨ê³„: ê°œë°œ ë„êµ¬ ì„¤ì¹˜ (ì„ íƒì‚¬í•­)
echo -e "\n${BLUE}ğŸ› ï¸ 7ë‹¨ê³„: ê°œë°œ ë„êµ¬ ì„¤ì¹˜ (ì„ íƒì‚¬í•­)${NC}"
read -p "ê°œë°œ ë„êµ¬(Jupyter, pytest ë“±)ë¥¼ ì„¤ì¹˜í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): " -n 1 -r
echo
if [[ $REPLY =~ ^[Yy]$ ]]; then
    pip install jupyter==1.0.0 notebook==7.0.6 ipykernel
    echo -e "${GREEN}âœ… ê°œë°œ ë„êµ¬ ì„¤ì¹˜ ì™„ë£Œ${NC}"
else
    echo "ê°œë°œ ë„êµ¬ ì„¤ì¹˜ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤."
fi

# 8ë‹¨ê³„: GPU ëª¨ë‹ˆí„°ë§ ë„êµ¬ ì„¤ì¹˜ (GPUê°€ ìˆëŠ” ê²½ìš°ë§Œ)
if [ "$GPU_AVAILABLE" = true ]; then
    echo -e "\n${BLUE}ğŸ“Š 8ë‹¨ê³„: GPU ëª¨ë‹ˆí„°ë§ ë„êµ¬ ì„¤ì¹˜${NC}"
    pip install nvidia-ml-py3==7.352.0 || {
        echo -e "${YELLOW}âš ï¸ GPU ëª¨ë‹ˆí„°ë§ ë„êµ¬ ì„¤ì¹˜ ì‹¤íŒ¨ (ì„ íƒì‚¬í•­)${NC}"
    }
fi

# 9ë‹¨ê³„: ì„¤ì¹˜ í™•ì¸ í…ŒìŠ¤íŠ¸
echo -e "\n${BLUE}ğŸ§ª 9ë‹¨ê³„: ì„¤ì¹˜ í™•ì¸ í…ŒìŠ¤íŠ¸${NC}"

# ê¸°ë³¸ import í…ŒìŠ¤íŠ¸
python -c "
import sys
print(f'Python: {sys.version}')

try:
    import torch
    print(f'âœ… PyTorch: {torch.__version__}')
    if torch.cuda.is_available():
        print(f'ğŸ® CUDA: {torch.version.cuda}')
        print(f'ğŸ® GPU ê°œìˆ˜: {torch.cuda.device_count()}')
    else:
        print('ğŸ’» CPU ëª¨ë“œ')
except ImportError as e:
    print(f'âŒ PyTorch import ì‹¤íŒ¨: {e}')

try:
    import fastapi
    print(f'âœ… FastAPI: {fastapi.__version__}')
except ImportError as e:
    print(f'âŒ FastAPI import ì‹¤íŒ¨: {e}')

try:
    import transformers
    print(f'âœ… Transformers: {transformers.__version__}')
except ImportError as e:
    print(f'âŒ Transformers import ì‹¤íŒ¨: {e}')

try:
    import streamlit
    print(f'âœ… Streamlit: {streamlit.__version__}')
except ImportError as e:
    print(f'âŒ Streamlit import ì‹¤íŒ¨: {e}')

try:
    import redis
    print(f'âœ… Redis: {redis.__version__}')
except ImportError as e:
    print(f'âŒ Redis import ì‹¤íŒ¨: {e}')

if '$GPU_AVAILABLE' == 'true':
    try:
        import vllm
        print(f'âœ… vLLM: {vllm.__version__}')
    except ImportError as e:
        print(f'âŒ vLLM import ì‹¤íŒ¨: {e}')
"

# ì„¤ì¹˜ ì™„ë£Œ ë©”ì‹œì§€
echo ""
echo "================================="
echo -e "${GREEN}ğŸ‰ íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì™„ë£Œ!${NC}"
echo "================================="
echo ""
echo -e "${BLUE}ğŸ“‹ ë‹¤ìŒ ë‹¨ê³„:${NC}"
echo "1. í•œêµ­ì–´ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ:"
echo "   python -c \"from transformers import AutoTokenizer; AutoTokenizer.from_pretrained('torchtorchkimtorch/Llama-3.2-Korean-GGACHI-1B-Instruct-v1', cache_dir='./tokenizer_cache')\""
echo ""
echo "2. Redis ì‹œì‘:"
echo "   docker run -d --name korean-redis -p 6379:6379 redis:alpine"
echo ""
echo "3. ì‹œìŠ¤í…œ ì‹œì‘:"
echo "   ./scripts/start_korean_system.sh"
echo ""
echo "4. í…ŒìŠ¤íŠ¸ ì‹¤í–‰:"
echo "   ./scripts/test_korean.sh"
echo ""

# ì„¤ì¹˜ëœ íŒ¨í‚¤ì§€ ëª©ë¡ ì €ì¥
echo -e "${BLUE}ğŸ“¦ ì„¤ì¹˜ëœ íŒ¨í‚¤ì§€ ëª©ë¡ ì €ì¥ ì¤‘...${NC}"
pip freeze > installed_packages.txt
echo -e "${GREEN}âœ… installed_packages.txtì— ì €ì¥ë¨${NC}"

echo -e "${GREEN}ì„¤ì¹˜ ì™„ë£Œ ì‹œê°„: $(date)${NC}"