#!/bin/bash
# í•œêµ­ì–´ Llama Token Limiter ì„¤ì¹˜ ìŠ¤í¬ë¦½íŠ¸

set -e

echo "ğŸ‡°ğŸ‡· í•œêµ­ì–´ Llama Token Limiter ì„¤ì¹˜ ì‹œì‘"
echo "=============================================="

# ìƒ‰ìƒ ì •ì˜
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# ì‹œìŠ¤í…œ ì •ë³´ ê°ì§€
detect_system() {
    echo -e "${BLUE}ğŸ” ì‹œìŠ¤í…œ ì •ë³´ ê°ì§€ ì¤‘...${NC}"

    # OS ê°ì§€
    if [[ "$OSTYPE" == "linux-gnu"* ]]; then
        OS="linux"
        if [ -f /etc/os-release ]; then
            . /etc/os-release
            DISTRO=$ID
            VERSION=$VERSION_ID
        fi
    elif [[ "$OSTYPE" == "darwin"* ]]; then
        OS="macos"
        DISTRO="macos"
    else
        echo -e "${RED}âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” ìš´ì˜ì²´ì œì…ë‹ˆë‹¤: $OSTYPE${NC}"
        exit 1
    fi

    echo "OS: $OS"
    echo "ë°°í¬íŒ: $DISTRO"

    # Python ë²„ì „ í™•ì¸
    if command -v python3.11 &> /dev/null; then
        PYTHON_CMD="python3.11"
    elif command -v python3.10 &> /dev/null; then
        PYTHON_CMD="python3.10"
    elif command -v python3.9 &> /dev/null; then
        PYTHON_CMD="python3.9"
    elif command -v python3 &> /dev/null; then
        PYTHON_CMD="python3"
    else
        echo -e "${RED}âŒ Python 3.9+ ê°€ í•„ìš”í•©ë‹ˆë‹¤${NC}"
        exit 1
    fi

    PYTHON_VERSION=$($PYTHON_CMD --version | cut -d' ' -f2)
    echo "Python: $PYTHON_VERSION"

    # GPU í™•ì¸
    if command -v nvidia-smi &> /dev/null; then
        GPU_AVAILABLE=true
        GPU_INFO=$(nvidia-smi --query-gpu=name,memory.total --format=csv,noheader,nounits | head -1)
        echo "GPU: $GPU_INFO"
    else
        GPU_AVAILABLE=false
        echo -e "${YELLOW}âš ï¸ NVIDIA GPUë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤${NC}"
    fi
}

# ì‹œìŠ¤í…œ ì˜ì¡´ì„± ì„¤ì¹˜
install_system_dependencies() {
    echo -e "\n${BLUE}ğŸ“¦ ì‹œìŠ¤í…œ ì˜ì¡´ì„± ì„¤ì¹˜ ì¤‘...${NC}"

    case $DISTRO in
        ubuntu|debian)
            sudo apt update
            sudo apt install -y \
                python3-pip python3-venv python3-dev \
                build-essential curl git wget \
                software-properties-common \
                pkg-config libffi-dev \
                redis-tools

            # Docker ì„¤ì¹˜ (ì„ íƒì‚¬í•­)
            if ! command -v docker &> /dev/null; then
                echo "Docker ì„¤ì¹˜ ì¤‘..."
                curl -fsSL https://get.docker.com -o get-docker.sh
                sudo sh get-docker.sh
                sudo usermod -aG docker $USER
                rm get-docker.sh
                echo -e "${GREEN}âœ… Docker ì„¤ì¹˜ ì™„ë£Œ${NC}"
            fi
            ;;
        centos|rhel|fedora)
            if command -v dnf &> /dev/null; then
                sudo dnf install -y python3-pip python3-devel gcc curl git wget redis
            else
                sudo yum install -y python3-pip python3-devel gcc curl git wget redis
            fi
            ;;
        macos)
            if ! command -v brew &> /dev/null; then
                echo "Homebrew ì„¤ì¹˜ ì¤‘..."
                /bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"
            fi
            brew install python redis git
            ;;
        *)
            echo -e "${YELLOW}âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” ë°°í¬íŒì…ë‹ˆë‹¤. ìˆ˜ë™ìœ¼ë¡œ ì˜ì¡´ì„±ì„ ì„¤ì¹˜í•´ì£¼ì„¸ìš”.${NC}"
            ;;
    esac

    echo -e "${GREEN}âœ… ì‹œìŠ¤í…œ ì˜ì¡´ì„± ì„¤ì¹˜ ì™„ë£Œ${NC}"
}

# NVIDIA ë“œë¼ì´ë²„ ë° CUDA ì„¤ì¹˜ í™•ì¸
check_nvidia_cuda() {
    if [ "$GPU_AVAILABLE" = true ]; then
        echo -e "\n${BLUE}ğŸ® NVIDIA/CUDA í™˜ê²½ í™•ì¸ ì¤‘...${NC}"

        # NVIDIA ë“œë¼ì´ë²„ í™•ì¸
        nvidia_version=$(nvidia-smi --query-gpu=driver_version --format=csv,noheader | head -1)
        echo "NVIDIA ë“œë¼ì´ë²„: $nvidia_version"

        # CUDA í™•ì¸
        if command -v nvcc &> /dev/null; then
            cuda_version=$(nvcc --version | grep "release" | sed 's/.*release \([0-9]\+\.[0-9]\+\).*/\1/')
            echo "CUDA: $cuda_version"
        else
            echo -e "${YELLOW}âš ï¸ CUDA Toolkitì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤${NC}"
            echo "vLLM ì„¤ì¹˜ë¥¼ ìœ„í•´ CUDA 12.1+ ê¶Œì¥"

            read -p "CUDA Toolkitì„ ì„¤ì¹˜í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): " -n 1 -r
            echo
            if [[ $REPLY =~ ^[Yy]$ ]]; then
                install_cuda
            fi
        fi
    fi
}

# CUDA ì„¤ì¹˜ í•¨ìˆ˜
install_cuda() {
    echo -e "${BLUE}ğŸ”§ CUDA Toolkit ì„¤ì¹˜ ì¤‘...${NC}"

    case $DISTRO in
        ubuntu)
            # Ubuntu 22.04 ê¸°ì¤€ CUDA 12.1 ì„¤ì¹˜
            wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-keyring_1.0-1_all.deb
            sudo dpkg -i cuda-keyring_1.0-1_all.deb
            sudo apt-get update
            sudo apt-get -y install cuda-toolkit-12-1
            rm cuda-keyring_1.0-1_all.deb

            # í™˜ê²½ë³€ìˆ˜ ì„¤ì •
            echo 'export PATH=/usr/local/cuda-12.1/bin:$PATH' >> ~/.bashrc
            echo 'export LD_LIBRARY_PATH=/usr/local/cuda-12.1/lib64:$LD_LIBRARY_PATH' >> ~/.bashrc
            ;;
        *)
            echo -e "${YELLOW}âš ï¸ ìë™ CUDA ì„¤ì¹˜ëŠ” Ubuntuë§Œ ì§€ì›í•©ë‹ˆë‹¤${NC}"
            echo "ìˆ˜ë™ìœ¼ë¡œ CUDAë¥¼ ì„¤ì¹˜í•´ì£¼ì„¸ìš”: https://developer.nvidia.com/cuda-downloads"
            ;;
    esac
}

# Python ê°€ìƒí™˜ê²½ ì„¤ì •
setup_python_env() {
    echo -e "\n${BLUE}ğŸ Python ê°€ìƒí™˜ê²½ ì„¤ì • ì¤‘...${NC}"

    # ê¸°ì¡´ ê°€ìƒí™˜ê²½ ë°±ì—…
    if [ -d "venv" ]; then
        echo "ê¸°ì¡´ ê°€ìƒí™˜ê²½ ë°±ì—… ì¤‘..."
        mv venv venv_backup_$(date +%Y%m%d_%H%M%S)
    fi

    # ìƒˆ ê°€ìƒí™˜ê²½ ìƒì„±
    $PYTHON_CMD -m venv venv
    source venv/bin/activate

    # pip ì—…ê·¸ë ˆì´ë“œ
    pip install --upgrade pip wheel setuptools

    echo -e "${GREEN}âœ… Python ê°€ìƒí™˜ê²½ ì„¤ì • ì™„ë£Œ${NC}"
}

# Python íŒ¨í‚¤ì§€ ì„¤ì¹˜
install_python_packages() {
    echo -e "\n${BLUE}ğŸ“š Python íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì¤‘...${NC}"

    # ê°€ìƒí™˜ê²½ì´ í™œì„±í™”ë˜ì—ˆëŠ”ì§€ í™•ì¸
    if [[ "$VIRTUAL_ENV" == "" ]]; then
        source venv/bin/activate
    fi

    # GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ì— ë”°ë¥¸ PyTorch ì„¤ì¹˜
    if [ "$GPU_AVAILABLE" = true ]; then
        echo "GPUìš© PyTorch ì„¤ì¹˜ ì¤‘..."
        pip install torch==2.1.0 torchvision==0.16.0 torchaudio==2.1.0 --index-url https://download.pytorch.org/whl/cu121
    else
        echo "CPUìš© PyTorch ì„¤ì¹˜ ì¤‘..."
        pip install torch==2.1.0 torchvision==0.16.0 torchaudio==2.1.0 --index-url https://download.pytorch.org/whl/cpu
    fi

    # vLLM ì„¤ì¹˜ (GPUê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ)
    if [ "$GPU_AVAILABLE" = true ]; then
        echo "vLLM ì„¤ì¹˜ ì¤‘..."
        pip install vllm==0.2.7

        # Flash Attention ì„¤ì¹˜ (ì„ íƒì‚¬í•­)
        echo "Flash Attention ì„¤ì¹˜ ì¤‘..."
        pip install flash-attn==2.3.4 --no-build-isolation || echo "âš ï¸ Flash Attention ì„¤ì¹˜ ì‹¤íŒ¨ (ì„ íƒì‚¬í•­)"

        # xformers ì„¤ì¹˜
        pip install xformers==0.0.22.post7 || echo "âš ï¸ xformers ì„¤ì¹˜ ì‹¤íŒ¨ (ì„ íƒì‚¬í•­)"
    else
        echo -e "${YELLOW}âš ï¸ GPUê°€ ì—†ì–´ vLLMì„ ê±´ë„ˆëœë‹ˆë‹¤${NC}"
    fi

    # ë‚˜ë¨¸ì§€ íŒ¨í‚¤ì§€ ì„¤ì¹˜
    echo "ê¸°ë³¸ íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì¤‘..."
    pip install -r requirements.txt

    echo -e "${GREEN}âœ… Python íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì™„ë£Œ${NC}"
}

# í•œêµ­ì–´ ì–¸ì–´ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
download_korean_model() {
    echo -e "\n${BLUE}ğŸ‡°ğŸ‡· í•œêµ­ì–´ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤‘...${NC}"

    if [[ "$VIRTUAL_ENV" == "" ]]; then
        source venv/bin/activate
    fi

    python3 -c "
try:
    from transformers import AutoTokenizer
    print('í•œêµ­ì–´ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹œì‘...')
    tokenizer = AutoTokenizer.from_pretrained(
        'torchtorchkimtorch/Llama-3.2-Korean-GGACHI-1B-Instruct-v1',
        cache_dir='./tokenizer_cache',
        trust_remote_code=True
    )
    print(f'âœ… í† í¬ë‚˜ì´ì € ë‹¤ìš´ë¡œë“œ ì™„ë£Œ (ì–´íœ˜ í¬ê¸°: {len(tokenizer):,})')

    # í† í° í…ŒìŠ¤íŠ¸
    test_text = 'ì•ˆë…•í•˜ì„¸ìš”! í•œêµ­ì–´ í† í° í…ŒìŠ¤íŠ¸ì…ë‹ˆë‹¤.'
    tokens = tokenizer.encode(test_text)
    print(f'í…ŒìŠ¤íŠ¸ í† í° ìˆ˜: {len(tokens)}ê°œ')
    print('âœ… í•œêµ­ì–´ í† í°í™” í…ŒìŠ¤íŠ¸ ì„±ê³µ')

except Exception as e:
    print(f'âŒ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}')
    exit(1)
"

    if [ $? -eq 0 ]; then
        echo -e "${GREEN}âœ… í•œêµ­ì–´ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ${NC}"
    else
        echo -e "${RED}âŒ í•œêµ­ì–´ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨${NC}"
        exit 1
    fi
}

# í”„ë¡œì íŠ¸ êµ¬ì¡° ì„¤ì •
setup_project_structure() {
    echo -e "\n${BLUE}ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡° ì„¤ì • ì¤‘...${NC}"

    # í•„ìš”í•œ ë””ë ‰í† ë¦¬ ìƒì„±
    mkdir -p {src/{core,storage,proxy,utils},config,dashboard,logs,tests,pids,tokenizer_cache,backups}

    # ë¡œê·¸ ë””ë ‰í† ë¦¬ ê¶Œí•œ ì„¤ì •
    chmod 755 logs

    # ì„¤ì • íŒŒì¼ ê²€ì¦
    if [ ! -f "config/korean_model.yaml" ]; then
        echo -e "${RED}âŒ config/korean_model.yaml íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤${NC}"
        exit 1
    fi

    if [ ! -f "config/korean_users.yaml" ]; then
        echo -e "${RED}âŒ config/korean_users.yaml íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤${NC}"
        exit 1
    fi

    # ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ê¶Œí•œ ì„¤ì •
    chmod +x scripts/*.sh 2>/dev/null || true

    # __init__.py íŒŒì¼ ìƒì„±
    touch src/__init__.py
    touch src/core/__init__.py
    touch src/storage/__init__.py

    echo -e "${GREEN}âœ… í”„ë¡œì íŠ¸ êµ¬ì¡° ì„¤ì • ì™„ë£Œ${NC}"
}

# í™˜ê²½ ì„¤ì • íŒŒì¼ ìƒì„±
create_env_file() {
    echo -e "\n${BLUE}âš™ï¸ í™˜ê²½ ì„¤ì • íŒŒì¼ ìƒì„± ì¤‘...${NC}"

    if [ ! -f ".env" ]; then
        cat > .env << EOF
# í•œêµ­ì–´ Llama Token Limiter í™˜ê²½ ì„¤ì •

# ì„œë²„ ì„¤ì •
SERVER_HOST=0.0.0.0
SERVER_PORT=8080
DEBUG=false

# LLM ì„œë²„ ì„¤ì •
LLM_SERVER_URL=http://localhost:8000
MODEL_NAME=torchtorchkimtorch/Llama-3.2-Korean-GGACHI-1B-Instruct-v1

# ì €ì¥ì†Œ ì„¤ì •
STORAGE_TYPE=redis
REDIS_URL=redis://localhost:6379
SQLITE_PATH=korean_usage.db

# ê¸°ë³¸ ì œí•œ ì„¤ì • (í•œêµ­ì–´ ëª¨ë¸ íŠ¹í™”)
DEFAULT_RPM=30
DEFAULT_TPM=5000
DEFAULT_TPH=300000
DEFAULT_DAILY=500000
DEFAULT_COOLDOWN=3

# í† í° ì„¤ì •
KOREAN_FACTOR=1.2
MAX_MODEL_LEN=2048
TOKENIZER_CACHE_DIR=./tokenizer_cache

# GPU ì„¤ì • (RTX 4060 8GB ìµœì í™”)
GPU_MEMORY_UTILIZATION=0.8
TENSOR_PARALLEL_SIZE=1
DTYPE=half
ENFORCE_EAGER=true

# ë¡œê¹… ì„¤ì •
LOG_LEVEL=INFO
LOG_FILE=logs/korean_token_limiter.log

# HuggingFace ì„¤ì • (ì„ íƒì‚¬í•­)
# HUGGINGFACE_TOKEN=your_token_here

# ê°œë°œ ëª¨ë“œ ì„¤ì •
DEVELOPMENT_MODE=true
ENABLE_CORS=true
EOF
        echo -e "${GREEN}âœ… .env íŒŒì¼ ìƒì„± ì™„ë£Œ${NC}"
    else
        echo -e "${YELLOW}âš ï¸ .env íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤${NC}"
    fi
}

# Redis ì„œë¹„ìŠ¤ í™•ì¸ ë° ì‹œì‘
setup_redis() {
    echo -e "\n${BLUE}ğŸ”´ Redis ì„¤ì • ì¤‘...${NC}"

    # Redisê°€ ì´ë¯¸ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸
    if redis-cli ping >/dev/null 2>&1; then
        echo -e "${GREEN}âœ… Redisê°€ ì´ë¯¸ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤${NC}"
        return 0
    fi

    # Dockerë¡œ Redis ì‹¤í–‰
    if command -v docker &> /dev/null; then
        echo "Dockerë¥¼ ì‚¬ìš©í•˜ì—¬ Redis ì‹œì‘..."

        # ê¸°ì¡´ ì»¨í…Œì´ë„ˆ ì •ë¦¬
        docker rm -f korean-redis 2>/dev/null || true

        # Redis ì»¨í…Œì´ë„ˆ ì‹œì‘
        docker run -d \
            --name korean-redis \
            -p 6379:6379 \
            --restart unless-stopped \
            redis:alpine \
            redis-server --appendonly yes --maxmemory 256mb --maxmemory-policy allkeys-lru

        # ì—°ê²° í™•ì¸
        echo "Redis ì—°ê²° ëŒ€ê¸° ì¤‘..."
        for i in {1..30}; do
            if redis-cli ping >/dev/null 2>&1; then
                echo -e "${GREEN}âœ… Redis ì—°ê²° í™•ì¸ë¨${NC}"
                return 0
            fi
            sleep 1
        done

        echo -e "${RED}âŒ Redis ì—°ê²° ì‹¤íŒ¨${NC}"
        return 1
    else
        echo -e "${YELLOW}âš ï¸ Dockerê°€ ì—†ì–´ì„œ Redisë¥¼ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤${NC}"
        echo "ìˆ˜ë™ìœ¼ë¡œ Redisë¥¼ ì„¤ì¹˜í•˜ê³  ì‹œì‘í•´ì£¼ì„¸ìš”"
        return 1
    fi
}

# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
run_tests() {
    echo -e "\n${BLUE}ğŸ§ª ê¸°ë³¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘...${NC}"

    if [[ "$VIRTUAL_ENV" == "" ]]; then
        source venv/bin/activate
    fi

    # ê¸°ë³¸ ëª¨ë“ˆ import í…ŒìŠ¤íŠ¸
    python3 -c "
import sys
sys.path.append('.')

try:
    from src.core.korean_token_counter import KoreanTokenCounter
    from src.core.config import Config
    print('âœ… í•µì‹¬ ëª¨ë“ˆ import ì„±ê³µ')

    # í† í° ì¹´ìš´í„° í…ŒìŠ¤íŠ¸
    counter = KoreanTokenCounter()
    test_text = 'ì•ˆë…•í•˜ì„¸ìš”! í•œêµ­ì–´ í† í° í…ŒìŠ¤íŠ¸ì…ë‹ˆë‹¤.'
    token_count = counter.count_tokens(test_text)
    print(f'âœ… í† í° ê³„ì‚° í…ŒìŠ¤íŠ¸ ì„±ê³µ: {token_count}ê°œ')

    # ì„¤ì • í…ŒìŠ¤íŠ¸
    config = Config()
    print(f'âœ… ì„¤ì • ë¡œë“œ ì„±ê³µ: {config.model_name}')

except Exception as e:
    print(f'âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}')
    sys.exit(1)
"

    if [ $? -eq 0 ]; then
        echo -e "${GREEN}âœ… ê¸°ë³¸ í…ŒìŠ¤íŠ¸ í†µê³¼${NC}"
    else
        echo -e "${RED}âŒ ê¸°ë³¸ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨${NC}"
        exit 1
    fi
}

# ì„¤ì¹˜ ì™„ë£Œ ì•ˆë‚´
show_completion_info() {
    echo ""
    echo "=============================================="
    echo -e "${GREEN}ğŸ‰ í•œêµ­ì–´ Llama Token Limiter ì„¤ì¹˜ ì™„ë£Œ!${NC}"
    echo "=============================================="
    echo ""
    echo "ğŸ“‹ ë‹¤ìŒ ë‹¨ê³„:"
    echo ""
    echo -e "${BLUE}1. í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ:${NC}"
    echo "   source venv/bin/activate"
    echo "   source .env"
    echo ""
    echo -e "${BLUE}2. ì‹œìŠ¤í…œ ì‹œì‘:${NC}"
    echo "   ./scripts/start_korean_system.sh"
    echo ""
    echo -e "${BLUE}3. í…ŒìŠ¤íŠ¸ ì‹¤í–‰:${NC}"
    echo "   ./scripts/test_korean.sh"
    echo ""
    echo -e "${BLUE}4. ì›¹ ì¸í„°í˜ì´ìŠ¤ ì ‘ì†:${NC}"
    echo "   ğŸ”— Token Limiter: http://localhost:8080/health"
    echo "   ğŸ”— vLLM API: http://localhost:8000/v1/models"
    echo ""
    echo -e "${BLUE}5. ì˜ˆì œ ìš”ì²­:${NC}"
    echo "   curl -X POST http://localhost:8080/v1/chat/completions \\"
    echo "     -H 'Content-Type: application/json' \\"
    echo "     -H 'Authorization: Bearer sk-user1-korean-key-def' \\"
    echo "     -d '{"
    echo "       \"model\": \"korean-llama\","
    echo "       \"messages\": [{"
    echo "         \"role\": \"user\","
    echo "         \"content\": \"ì•ˆë…•í•˜ì„¸ìš”! í•œêµ­ì–´ë¡œ ê°„ë‹¨í•œ ì¸ì‚¬ë¥¼ í•´ì£¼ì„¸ìš”.\""
    echo "       }],"
    echo "       \"max_tokens\": 100"
    echo "     }'"
    echo ""
    echo -e "${BLUE}ğŸ“š ë„ì›€ë§:${NC}"
    echo "   ./scripts/start_korean_system.sh --help"
    echo "   ./scripts/stop_korean_system.sh --help"
    echo ""
    echo -e "${BLUE}ğŸ”§ ë¬¸ì œ í•´ê²°:${NC}"
    echo "   - ë¡œê·¸ í™•ì¸: tail -f logs/token_limiter.log"
    echo "   - GPU ìƒíƒœ: nvidia-smi"
    echo "   - Redis ìƒíƒœ: redis-cli ping"
    echo ""

    if [ "$GPU_AVAILABLE" = true ]; then
        echo -e "${GREEN}ğŸ® GPU í™˜ê²½ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤!${NC}"
        echo "   vLLMìœ¼ë¡œ ê³ ì„±ëŠ¥ ì¶”ë¡ ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤."
    else
        echo -e "${YELLOW}âš ï¸ GPUê°€ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.${NC}"
        echo "   CPU ëª¨ë“œë¡œ ì‹¤í–‰ë˜ë©° ì„±ëŠ¥ì´ ì œí•œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    fi

    echo ""
    echo "ì„¤ì¹˜ ì™„ë£Œ ì‹œê°„: $(date)"
}

# ë©”ì¸ ì„¤ì¹˜ í•¨ìˆ˜
main_install() {
    echo "ì„¤ì¹˜ ì‹œì‘ ì‹œê°„: $(date)"
    echo ""

    # ë‹¨ê³„ë³„ ì„¤ì¹˜ ì‹¤í–‰
    detect_system
    install_system_dependencies

    if [ "$GPU_AVAILABLE" = true ]; then
        check_nvidia_cuda
    fi

    setup_python_env
    install_python_packages
    download_korean_model
    setup_project_structure
    create_env_file
    setup_redis
    run_tests
    show_completion_info
}

# ë„ì›€ë§ í‘œì‹œ
if [ "$1" = "--help" ] || [ "$1" = "-h" ]; then
    echo "í•œêµ­ì–´ Llama Token Limiter ì„¤ì¹˜ ìŠ¤í¬ë¦½íŠ¸"
    echo ""
    echo "ì‚¬ìš©ë²•:"
    echo "  $0              # ì „ì²´ ì„¤ì¹˜"
    echo "  $0 --gpu-only   # GPU ê´€ë ¨ êµ¬ì„±ìš”ì†Œë§Œ ì„¤ì¹˜"
    echo "  $0 --cpu-only   # CPU ì „ìš© ì„¤ì¹˜"
    echo "  $0 --help       # ì´ ë„ì›€ë§ í‘œì‹œ"
    echo ""
    echo "ì˜µì…˜:"
    echo "  --gpu-only      GPU ë° vLLM ê´€ë ¨ íŒ¨í‚¤ì§€ë§Œ ì„¤ì¹˜"
    echo "  --cpu-only      CPU ì „ìš©ìœ¼ë¡œ ì„¤ì¹˜ (vLLM ì œì™¸)"
    echo "  --skip-model    ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ê±´ë„ˆë›°ê¸°"
    echo "  --help, -h      ì´ ë„ì›€ë§ í‘œì‹œ"
    echo ""
    echo "ìš”êµ¬ì‚¬í•­:"
    echo "  - Python 3.9+"
    echo "  - NVIDIA GPU (ì„ íƒì‚¬í•­, ê³ ì„±ëŠ¥ì„ ìœ„í•´ ê¶Œì¥)"
    echo "  - CUDA 12.1+ (GPU ì‚¬ìš© ì‹œ)"
    echo "  - Docker (Redisìš©, ì„ íƒì‚¬í•­)"
    echo "  - 8GB+ RAM (16GB ê¶Œì¥)"
    echo "  - 10GB+ ë””ìŠ¤í¬ ê³µê°„"
    echo ""
    exit 0
fi

# CPU ì „ìš© ì„¤ì¹˜ ì˜µì…˜
if [ "$1" = "--cpu-only" ]; then
    echo -e "${YELLOW}âš ï¸ CPU ì „ìš© ì„¤ì¹˜ ëª¨ë“œ${NC}"
    GPU_AVAILABLE=false
fi

# GPU ì „ìš© ì„¤ì¹˜ ì˜µì…˜
if [ "$1" = "--gpu-only" ]; then
    echo -e "${BLUE}ğŸ® GPU ì „ìš© ì„¤ì¹˜ ëª¨ë“œ${NC}"
    # GPU ê´€ë ¨ íŒ¨í‚¤ì§€ë§Œ ì„¤ì¹˜í•˜ëŠ” ë³„ë„ ë¡œì§ í•„ìš”
fi

# ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ê±´ë„ˆë›°ê¸° ì˜µì…˜
if [ "$2" = "--skip-model" ] || [ "$1" = "--skip-model" ]; then
    SKIP_MODEL_DOWNLOAD=true
fi

# ë£¨íŠ¸ ê¶Œí•œ í™•ì¸
if [ "$EUID" -eq 0 ]; then
    echo -e "${RED}âŒ ë£¨íŠ¸ ê¶Œí•œìœ¼ë¡œ ì‹¤í–‰í•˜ì§€ ë§ˆì„¸ìš”${NC}"
    echo "ì¼ë°˜ ì‚¬ìš©ì ê³„ì •ìœ¼ë¡œ ì‹¤í–‰í•´ì£¼ì„¸ìš”"
    exit 1
fi

# ì¢…ë£Œ ì‹œê·¸ë„ ì²˜ë¦¬
cleanup_on_exit() {
    echo -e "\n${YELLOW}ğŸ›‘ ì„¤ì¹˜ ì¤‘ë‹¨ë¨${NC}"
    exit 1
}

# ì‹œê·¸ë„ í•¸ë“¤ëŸ¬ ë“±ë¡
trap cleanup_on_exit SIGINT SIGTERM

# ë©”ì¸ ì‹¤í–‰
main_install