# Docker 환경용 설정 파일

# 서버 설정
SERVER_HOST=0.0.0.0
SERVER_PORT=8080
DEBUG=false

# LLM 서버 설정 (Docker 컨테이너 간 통신)
LLM_SERVER_URL=http://vllm-server:8000
MODEL_NAME=torchtorchkimtorch/Llama-3.2-Korean-GGACHI-1B-Instruct-v1

# 저장소 설정 (Redis 컨테이너 사용)
STORAGE_TYPE=redis
REDIS_URL=redis://redis:6379
SQLITE_PATH=/app/data/korean_usage.db

# 기본 제한 설정 (Docker 환경 최적화)
DEFAULT_RPM=25
DEFAULT_TPM=4000
DEFAULT_TPH=240000
DEFAULT_DAILY=400000
DEFAULT_COOLDOWN=3

# 토큰 설정
KOREAN_FACTOR=1.2
MAX_MODEL_LEN=2048
TOKENIZER_CACHE_DIR=/app/tokenizer_cache

# GPU 설정 (컨테이너 환경)
GPU_MEMORY_UTILIZATION=0.75
TENSOR_PARALLEL_SIZE=1
DTYPE=half
ENFORCE_EAGER=true

# 로깅 설정
LOG_LEVEL=INFO
LOG_FILE=/app/logs/korean_token_limiter.log

# 컨테이너 환경 설정
PYTHONPATH=/app
PYTHONIOENCODING=utf-8
TZ=Asia/Seoul

# CUDA 설정
CUDA_VISIBLE_DEVICES=0
PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512

# 개발 모드 (Docker에서는 비활성화)
DEVELOPMENT_MODE=false
ENABLE_CORS=true

# 모니터링 설정
ENABLE_METRICS=true
METRICS_PORT=9090

# 보안 설정
API_KEY_REQUIRED=true
RATE_LIMIT_BY_IP=false

# HuggingFace 설정 (필요시 설정)
# HUGGINGFACE_TOKEN=your_token_here